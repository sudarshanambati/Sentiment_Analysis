{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import re\n",
    "import time\n",
    "import string\n",
    "import warnings\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- clean_covid19au"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tweets</th>\n",
       "      <th>tidy_tweets</th>\n",
       "      <th>absolute_tidy_tweets</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-30 02:49:20+00:00</td>\n",
       "      <td>Talking all things Queensland borders at today...</td>\n",
       "      <td>Talking all things Queensland borders at today...</td>\n",
       "      <td>Talking thing Queensland border today presser</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-29 03:12:56+00:00</td>\n",
       "      <td>All hand sanitiser sold in Australia should co...</td>\n",
       "      <td>All hand sanitiser sold in Australia should co...</td>\n",
       "      <td>All hand sanitiser sold Australia contain enou...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-29 00:47:25+00:00</td>\n",
       "      <td>Saturday night a blokes night will occur as ou...</td>\n",
       "      <td>Saturday night a blokes night will occur as ou...</td>\n",
       "      <td>Saturday night bloke night occur wife go annua...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       date  \\\n",
       "0           0  2020-10-30 02:49:20+00:00   \n",
       "1           1  2020-10-29 03:12:56+00:00   \n",
       "2           2  2020-10-29 00:47:25+00:00   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  Talking all things Queensland borders at today...   \n",
       "1  All hand sanitiser sold in Australia should co...   \n",
       "2  Saturday night a blokes night will occur as ou...   \n",
       "\n",
       "                                         tidy_tweets  \\\n",
       "0  Talking all things Queensland borders at today...   \n",
       "1  All hand sanitiser sold in Australia should co...   \n",
       "2  Saturday night a blokes night will occur as ou...   \n",
       "\n",
       "                                absolute_tidy_tweets sentiment  \n",
       "0      Talking thing Queensland border today presser   neutral  \n",
       "1  All hand sanitiser sold Australia contain enou...       pos  \n",
       "2  Saturday night bloke night occur wife go annua...       pos  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df2=pd.read_csv(\"clean_covid19au.csv\")\n",
    "tweets_df2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac943fa645c528c6cee36de60e9fbdd8be384cdd"
   },
   "source": [
    "## <a id='5'>5. Feature Extraction</a>\n",
    "\n",
    "We need to convert textual representation in the form on numeric features. We have a popular techniques to perform feature extraction:\n",
    "\n",
    "\n",
    "1. __TF-IDF (Term Frequency - Inverse Document Frequency)__\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "622ce8acd9e96e232d3a9b6d526ee7ca675f5a55"
   },
   "source": [
    "### <a id='5A'>A. Feature Extraction for 'Key Words'</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "a92ca10bbce43b9a01faef3dff8b6bc5da5f8c6b"
   },
   "outputs": [],
   "source": [
    "# TF-IDF features\n",
    "tfidf_word_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, stop_words='english')\n",
    "# TF-IDF feature matrix\n",
    "tfidf_word_feature = tfidf_word_vectorizer.fit_transform(tweets_df2['absolute_tidy_tweets'].astype('U'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c374d7527da7c24177cc42e3c2b3b1a87c9e38a"
   },
   "source": [
    "## <a id='6'>6. Model Building: Sentiment Analysis</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ad9171efab73b4305acb6f29de3519285fbf9448"
   },
   "source": [
    "#### Map target variables to  {0, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "f4ec7bc53e1233f856e5d5fe60d2681d88f881b1"
   },
   "outputs": [],
   "source": [
    "target_variable = tweets_df2['sentiment'].apply(lambda x: -1 if x=='neg' else (1 if x==\"pos\" else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "bae6f1c0864306af8264bcd4e74ab2d8ab9a8c17"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_word_feature, target_variable, test_size=0.3, random_state=272)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "R_model = randomforest.fit(X_train,y_train)\n",
    "R_predict=R_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "1-Confusion matrix <br>\n",
    "2-Accuray <br>\n",
    "3-F1 score <br>\n",
    "4-Other matrix<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[274  81  34]\n",
      " [ 50 179  12]\n",
      " [ 87  50 123]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "\n",
    "matrix = confusion_matrix(y_test,R_predict, labels=[1, 0,-1])\n",
    "print(\"Confusion matrix\")\n",
    "print(matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.70      0.68       389\n",
      "           0       0.58      0.74      0.65       241\n",
      "          -1       0.73      0.47      0.57       260\n",
      "\n",
      "    accuracy                           0.65       890\n",
      "   macro avg       0.66      0.64      0.64       890\n",
      "weighted avg       0.66      0.65      0.64       890\n",
      "\n",
      "\n",
      "\n",
      "The accuracy of the model is =  0.647191011235955\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test,R_predict,labels=[1,0,-1])\n",
    "print('\\nClassification report : \\n',matrix)\n",
    "\n",
    "# Accuracy\n",
    "print(\"\\n\\nThe accuracy of the model is = \", accuracy_score(y_test,R_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Logistic Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create logistic regression object\n",
    "logistic_regression = LogisticRegression(multi_class='multinomial', solver='newton-cg',random_state=0)\n",
    "# Train model\n",
    "L_model = logistic_regression.fit(X_train,y_train)\n",
    "L_predict=L_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "1-Confusion matrix <br>\n",
    "2-Accuray <br>\n",
    "3-F1 score <br>\n",
    "4-Other matrix<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[338  12  39]\n",
      " [134  70  37]\n",
      " [123   8 129]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test,L_predict, labels=[1,0,-1])\n",
    "#plot_confusion_matrix(matrix)\n",
    "print(\"Confusion matrix\")\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.87      0.69       389\n",
      "           0       0.78      0.29      0.42       241\n",
      "          -1       0.63      0.50      0.55       260\n",
      "\n",
      "    accuracy                           0.60       890\n",
      "   macro avg       0.66      0.55      0.55       890\n",
      "weighted avg       0.64      0.60      0.58       890\n",
      "\n",
      "\n",
      "\n",
      "The accuracy of the model is =  0.6033707865168539\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test,L_predict,labels=[1,0,-1])\n",
    "print('\\nClassification report : \\n',matrix)\n",
    "\n",
    "# Accuracy\n",
    "print(\"\\n\\nThe accuracy of the model is = \", accuracy_score(y_test,L_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto'))\n",
    "clf.fit(X_train, y_train)\n",
    "svm_predict=clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Testing the model\n",
    "1-Confusion matrix <br>\n",
    "2-Accuray <br>\n",
    "3-F1 score <br>\n",
    "4-Other matrix<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[357  21  11]\n",
      " [145  89   7]\n",
      " [216   5  39]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test,svm_predict, labels=[1,0,-1])\n",
    "#plot_confusion_matrix(matrix)\n",
    "print(\"Confusion matrix\")\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.92      0.64       389\n",
      "           0       0.77      0.37      0.50       241\n",
      "\n",
      "   micro avg       0.54      0.71      0.61       630\n",
      "   macro avg       0.64      0.64      0.57       630\n",
      "weighted avg       0.60      0.71      0.59       630\n",
      "\n",
      "\n",
      "\n",
      "The accuracy of the model is =  0.5449438202247191\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test,svm_predict,labels=[1,0])\n",
    "print('\\nClassification report : \\n',matrix)\n",
    "\n",
    "# Accuracy\n",
    "print(\"\\n\\nThe accuracy of the model is = \", accuracy_score(y_test,svm_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- clean_lockdown_senti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tweets</th>\n",
       "      <th>tidy_tweets</th>\n",
       "      <th>absolute_tidy_tweets</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-30 23:56:05+00:00</td>\n",
       "      <td>Lockdown works in the short term. But is it ul...</td>\n",
       "      <td>Lockdown works in the short term. But is it ul...</td>\n",
       "      <td>Lockdown work short term But ultimately best s...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-30 23:48:39+00:00</td>\n",
       "      <td>Just to finish off Inktober2020 with a smile. ...</td>\n",
       "      <td>Just to finish off Inktober2020 with a smile. ...</td>\n",
       "      <td>Just finish Inktober smile Thank reacted comme...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-30 23:32:28+00:00</td>\n",
       "      <td>Lmao Melb defs going into a 3rd and 4th lockdo...</td>\n",
       "      <td>Lmao Melb defs going into a 3rd and 4th lockdo...</td>\n",
       "      <td>Lmao Melb defs going rd th lockdown People ful...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       date  \\\n",
       "0           0  2020-10-30 23:56:05+00:00   \n",
       "1           1  2020-10-30 23:48:39+00:00   \n",
       "2           2  2020-10-30 23:32:28+00:00   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  Lockdown works in the short term. But is it ul...   \n",
       "1  Just to finish off Inktober2020 with a smile. ...   \n",
       "2  Lmao Melb defs going into a 3rd and 4th lockdo...   \n",
       "\n",
       "                                         tidy_tweets  \\\n",
       "0  Lockdown works in the short term. But is it ul...   \n",
       "1  Just to finish off Inktober2020 with a smile. ...   \n",
       "2  Lmao Melb defs going into a 3rd and 4th lockdo...   \n",
       "\n",
       "                                absolute_tidy_tweets sentiment  \n",
       "0  Lockdown work short term But ultimately best s...       pos  \n",
       "1  Just finish Inktober smile Thank reacted comme...       pos  \n",
       "2  Lmao Melb defs going rd th lockdown People ful...       pos  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df2=pd.read_csv(\"clean_lockdown_senti.csv\")\n",
    "tweets_df2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac943fa645c528c6cee36de60e9fbdd8be384cdd"
   },
   "source": [
    "## <a id='5'>5. Feature Extraction</a>\n",
    "\n",
    "We need to convert textual representation in the form on numeric features. We have a popular techniques to perform feature extraction:\n",
    "\n",
    "\n",
    "1. __TF-IDF (Term Frequency - Inverse Document Frequency)__\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "622ce8acd9e96e232d3a9b6d526ee7ca675f5a55"
   },
   "source": [
    "### <a id='5A'>A. Feature Extraction for 'Key Words'</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "a92ca10bbce43b9a01faef3dff8b6bc5da5f8c6b"
   },
   "outputs": [],
   "source": [
    "# TF-IDF features\n",
    "tfidf_word_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, stop_words='english')\n",
    "# TF-IDF feature matrix\n",
    "tfidf_word_feature = tfidf_word_vectorizer.fit_transform(tweets_df2['absolute_tidy_tweets'].astype('U'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c374d7527da7c24177cc42e3c2b3b1a87c9e38a"
   },
   "source": [
    "## <a id='6'>6. Model Building: Sentiment Analysis</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ad9171efab73b4305acb6f29de3519285fbf9448"
   },
   "source": [
    "#### Map target variables to  {0, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "f4ec7bc53e1233f856e5d5fe60d2681d88f881b1"
   },
   "outputs": [],
   "source": [
    "target_variable = tweets_df2['sentiment'].apply(lambda x: -1 if x=='neg' else (1 if x==\"pos\" else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "bae6f1c0864306af8264bcd4e74ab2d8ab9a8c17"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_word_feature, target_variable, test_size=0.3, random_state=272)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "R_model = randomforest.fit(X_train,y_train)\n",
    "R_predict=R_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "1-Confusion matrix <br>\n",
    "2-Accuray <br>\n",
    "3-F1 score <br>\n",
    "4-Other matrix<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[1534  232  144]\n",
      " [ 175  799   64]\n",
      " [ 422  186  498]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "\n",
    "matrix = confusion_matrix(y_test,R_predict, labels=[1, 0,-1])\n",
    "print(\"Confusion matrix\")\n",
    "print(matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.80      0.76      1910\n",
      "           0       0.66      0.77      0.71      1038\n",
      "          -1       0.71      0.45      0.55      1106\n",
      "\n",
      "    accuracy                           0.70      4054\n",
      "   macro avg       0.69      0.67      0.67      4054\n",
      "weighted avg       0.70      0.70      0.69      4054\n",
      "\n",
      "\n",
      "\n",
      "The accuracy of the model is =  0.698322644301924\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test,R_predict,labels=[1,0,-1])\n",
    "print('\\nClassification report : \\n',matrix)\n",
    "\n",
    "# Accuracy\n",
    "print(\"\\n\\nThe accuracy of the model is = \", accuracy_score(y_test,R_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Logistic Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create logistic regression object\n",
    "logistic_regression = LogisticRegression(multi_class='multinomial', solver='newton-cg',random_state=0)\n",
    "# Train model\n",
    "L_model = logistic_regression.fit(X_train,y_train)\n",
    "L_predict=L_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "1-Confusion matrix <br>\n",
    "2-Accuray <br>\n",
    "3-F1 score <br>\n",
    "4-Other matrix<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[1648  105  157]\n",
      " [ 263  678   97]\n",
      " [ 346  115  645]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test,L_predict, labels=[1,0,-1])\n",
    "#plot_confusion_matrix(matrix)\n",
    "print(\"Confusion matrix\")\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.86      0.79      1910\n",
      "           0       0.76      0.65      0.70      1038\n",
      "          -1       0.72      0.58      0.64      1106\n",
      "\n",
      "    accuracy                           0.73      4054\n",
      "   macro avg       0.73      0.70      0.71      4054\n",
      "weighted avg       0.73      0.73      0.73      4054\n",
      "\n",
      "\n",
      "\n",
      "The accuracy of the model is =  0.7328564380858411\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test,L_predict,labels=[1,0,-1])\n",
    "print('\\nClassification report : \\n',matrix)\n",
    "\n",
    "# Accuracy\n",
    "print(\"\\n\\nThe accuracy of the model is = \", accuracy_score(y_test,L_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto'))\n",
    "clf.fit(X_train, y_train)\n",
    "svm_predict=clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Testing the model\n",
    "1-Confusion matrix <br>\n",
    "2-Accuray <br>\n",
    "3-F1 score <br>\n",
    "4-Other matrix<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[1770   63   77]\n",
      " [ 614  374   50]\n",
      " [ 758   38  310]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test,svm_predict, labels=[1,0,-1])\n",
    "#plot_confusion_matrix(matrix)\n",
    "print(\"Confusion matrix\")\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.93      0.70      1910\n",
      "           0       0.79      0.36      0.49      1038\n",
      "\n",
      "   micro avg       0.59      0.73      0.65      2948\n",
      "   macro avg       0.68      0.64      0.60      2948\n",
      "weighted avg       0.64      0.73      0.63      2948\n",
      "\n",
      "\n",
      "\n",
      "The accuracy of the model is =  0.6053280710409472\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test,svm_predict,labels=[1,0])\n",
    "print('\\nClassification report : \\n',matrix)\n",
    "\n",
    "# Accuracy\n",
    "print(\"\\n\\nThe accuracy of the model is = \", accuracy_score(y_test,svm_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- clean_mask_senti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tweets</th>\n",
       "      <th>tidy_tweets</th>\n",
       "      <th>absolute_tidy_tweets</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-12-31 23:46:53+00:00</td>\n",
       "      <td>The Victorian Health Minister has clarified ru...</td>\n",
       "      <td>The Victorian Health Minister has clarified ru...</td>\n",
       "      <td>The Victorian Health Minister clarified rule a...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-31 23:22:47+00:00</td>\n",
       "      <td>@Michael01996367 @elonmusk @Tesla @TeslaGong @...</td>\n",
       "      <td>@Michael01996367 @elonmusk @Tesla @TeslaGong @...</td>\n",
       "      <td>Michael elonmusk Tesla TeslaGong TeslaTom Tesl...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-12-31 22:46:38+00:00</td>\n",
       "      <td>Mask 😷 wearing deemed to be too much of a burd...</td>\n",
       "      <td>Mask 😷 wearing deemed to be too much of a burd...</td>\n",
       "      <td>Mask wearing deemed much burden ppl NSW accord...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       date  \\\n",
       "0           0  2020-12-31 23:46:53+00:00   \n",
       "1           1  2020-12-31 23:22:47+00:00   \n",
       "2           2  2020-12-31 22:46:38+00:00   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  The Victorian Health Minister has clarified ru...   \n",
       "1  @Michael01996367 @elonmusk @Tesla @TeslaGong @...   \n",
       "2  Mask 😷 wearing deemed to be too much of a burd...   \n",
       "\n",
       "                                         tidy_tweets  \\\n",
       "0  The Victorian Health Minister has clarified ru...   \n",
       "1  @Michael01996367 @elonmusk @Tesla @TeslaGong @...   \n",
       "2  Mask 😷 wearing deemed to be too much of a burd...   \n",
       "\n",
       "                                absolute_tidy_tweets sentiment  \n",
       "0  The Victorian Health Minister clarified rule a...       pos  \n",
       "1  Michael elonmusk Tesla TeslaGong TeslaTom Tesl...   neutral  \n",
       "2  Mask wearing deemed much burden ppl NSW accord...       neg  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df2=pd.read_csv(\"clean_mask_senti.csv\")\n",
    "tweets_df2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac943fa645c528c6cee36de60e9fbdd8be384cdd"
   },
   "source": [
    "## <a id='5'>5. Feature Extraction</a>\n",
    "\n",
    "We need to convert textual representation in the form on numeric features. We have a popular techniques to perform feature extraction:\n",
    "\n",
    "\n",
    "1. __TF-IDF (Term Frequency - Inverse Document Frequency)__\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "622ce8acd9e96e232d3a9b6d526ee7ca675f5a55"
   },
   "source": [
    "### <a id='5A'>A. Feature Extraction for 'Key Words'</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_uuid": "a92ca10bbce43b9a01faef3dff8b6bc5da5f8c6b"
   },
   "outputs": [],
   "source": [
    "# TF-IDF features\n",
    "tfidf_word_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, stop_words='english')\n",
    "# TF-IDF feature matrix\n",
    "tfidf_word_feature = tfidf_word_vectorizer.fit_transform(tweets_df2['absolute_tidy_tweets'].astype('U'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c374d7527da7c24177cc42e3c2b3b1a87c9e38a"
   },
   "source": [
    "## <a id='6'>6. Model Building: Sentiment Analysis</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ad9171efab73b4305acb6f29de3519285fbf9448"
   },
   "source": [
    "#### Map target variables to  {0, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_uuid": "f4ec7bc53e1233f856e5d5fe60d2681d88f881b1"
   },
   "outputs": [],
   "source": [
    "target_variable = tweets_df2['sentiment'].apply(lambda x: -1 if x=='neg' else (1 if x==\"pos\" else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_uuid": "bae6f1c0864306af8264bcd4e74ab2d8ab9a8c17"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_word_feature, target_variable, test_size=0.3, random_state=272)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "R_model = randomforest.fit(X_train,y_train)\n",
    "R_predict=R_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "1-Confusion matrix <br>\n",
    "2-Accuray <br>\n",
    "3-F1 score <br>\n",
    "4-Other matrix<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[1483  207   31]\n",
      " [ 221  831   16]\n",
      " [ 422  163  206]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "\n",
    "matrix = confusion_matrix(y_test,R_predict, labels=[1, 0,-1])\n",
    "print(\"Confusion matrix\")\n",
    "print(matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.86      0.77      1721\n",
      "           0       0.69      0.78      0.73      1068\n",
      "          -1       0.81      0.26      0.39       791\n",
      "\n",
      "    accuracy                           0.70      3580\n",
      "   macro avg       0.73      0.63      0.63      3580\n",
      "weighted avg       0.72      0.70      0.68      3580\n",
      "\n",
      "\n",
      "\n",
      "The accuracy of the model is =  0.7039106145251397\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test,R_predict,labels=[1,0,-1])\n",
    "print('\\nClassification report : \\n',matrix)\n",
    "\n",
    "# Accuracy\n",
    "print(\"\\n\\nThe accuracy of the model is = \", accuracy_score(y_test,R_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Logistic Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create logistic regression object\n",
    "logistic_regression = LogisticRegression(multi_class='multinomial', solver='newton-cg',random_state=0)\n",
    "# Train model\n",
    "L_model = logistic_regression.fit(X_train,y_train)\n",
    "L_predict=L_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "1-Confusion matrix <br>\n",
    "2-Accuray <br>\n",
    "3-F1 score <br>\n",
    "4-Other matrix<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[1536  113   72]\n",
      " [ 268  745   55]\n",
      " [ 328  130  333]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test,L_predict, labels=[1,0,-1])\n",
    "#plot_confusion_matrix(matrix)\n",
    "print(\"Confusion matrix\")\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.89      0.80      1721\n",
      "           0       0.75      0.70      0.72      1068\n",
      "          -1       0.72      0.42      0.53       791\n",
      "\n",
      "    accuracy                           0.73      3580\n",
      "   macro avg       0.73      0.67      0.68      3580\n",
      "weighted avg       0.73      0.73      0.72      3580\n",
      "\n",
      "\n",
      "\n",
      "The accuracy of the model is =  0.7301675977653631\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test,L_predict,labels=[1,0,-1])\n",
    "print('\\nClassification report : \\n',matrix)\n",
    "\n",
    "# Accuracy\n",
    "print(\"\\n\\nThe accuracy of the model is = \", accuracy_score(y_test,L_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto'))\n",
    "clf.fit(X_train, y_train)\n",
    "svm_predict=clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Testing the model\n",
    "1-Confusion matrix <br>\n",
    "2-Accuray <br>\n",
    "3-F1 score <br>\n",
    "4-Other matrix<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[1606  109    6]\n",
      " [ 654  405    9]\n",
      " [ 655   63   73]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test,svm_predict, labels=[1,0,-1])\n",
    "#plot_confusion_matrix(matrix)\n",
    "print(\"Confusion matrix\")\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.93      0.69      1721\n",
      "           0       0.70      0.38      0.49      1068\n",
      "\n",
      "   micro avg       0.58      0.72      0.64      2789\n",
      "   macro avg       0.63      0.66      0.59      2789\n",
      "weighted avg       0.61      0.72      0.62      2789\n",
      "\n",
      "\n",
      "\n",
      "The accuracy of the model is =  0.582122905027933\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test,svm_predict,labels=[1,0])\n",
    "print('\\nClassification report : \\n',matrix)\n",
    "\n",
    "# Accuracy\n",
    "print(\"\\n\\nThe accuracy of the model is = \", accuracy_score(y_test,svm_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- clean_quarantine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tweets</th>\n",
       "      <th>tidy_tweets</th>\n",
       "      <th>absolute_tidy_tweets</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-30 21:22:16+00:00</td>\n",
       "      <td>quarantine?</td>\n",
       "      <td>quarantine?</td>\n",
       "      <td>quarantine</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-30 20:10:28+00:00</td>\n",
       "      <td>cristiano ronaldo tested negative covid 19 qua...</td>\n",
       "      <td>cristiano ronaldo tested negative covid 19 qua...</td>\n",
       "      <td>cristiano ronaldo tested negative covid quaran...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-30 19:09:21+00:00</td>\n",
       "      <td>evening cravings 💕 hightea quarantine style co...</td>\n",
       "      <td>evening cravings 💕 hightea quarantine style co...</td>\n",
       "      <td>evening craving hightea quarantine style cooky...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       date  \\\n",
       "0           0  2020-10-30 21:22:16+00:00   \n",
       "1           1  2020-10-30 20:10:28+00:00   \n",
       "2           2  2020-10-30 19:09:21+00:00   \n",
       "\n",
       "                                              tweets  \\\n",
       "0                                        quarantine?   \n",
       "1  cristiano ronaldo tested negative covid 19 qua...   \n",
       "2  evening cravings 💕 hightea quarantine style co...   \n",
       "\n",
       "                                         tidy_tweets  \\\n",
       "0                                        quarantine?   \n",
       "1  cristiano ronaldo tested negative covid 19 qua...   \n",
       "2  evening cravings 💕 hightea quarantine style co...   \n",
       "\n",
       "                                absolute_tidy_tweets sentiment  \n",
       "0                                         quarantine   neutral  \n",
       "1  cristiano ronaldo tested negative covid quaran...       neg  \n",
       "2  evening craving hightea quarantine style cooky...   neutral  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df2=pd.read_csv(\"clean_quarantine.csv\")\n",
    "tweets_df2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac943fa645c528c6cee36de60e9fbdd8be384cdd"
   },
   "source": [
    "## <a id='5'>5. Feature Extraction</a>\n",
    "\n",
    "We need to convert textual representation in the form on numeric features. We have a popular techniques to perform feature extraction:\n",
    "\n",
    "\n",
    "1. __TF-IDF (Term Frequency - Inverse Document Frequency)__\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "622ce8acd9e96e232d3a9b6d526ee7ca675f5a55"
   },
   "source": [
    "### <a id='5A'>A. Feature Extraction for 'Key Words'</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "_uuid": "a92ca10bbce43b9a01faef3dff8b6bc5da5f8c6b"
   },
   "outputs": [],
   "source": [
    "# TF-IDF features\n",
    "tfidf_word_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, stop_words='english')\n",
    "# TF-IDF feature matrix\n",
    "tfidf_word_feature = tfidf_word_vectorizer.fit_transform(tweets_df2['absolute_tidy_tweets'].astype('U'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c374d7527da7c24177cc42e3c2b3b1a87c9e38a"
   },
   "source": [
    "## <a id='6'>6. Model Building: Sentiment Analysis</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ad9171efab73b4305acb6f29de3519285fbf9448"
   },
   "source": [
    "#### Map target variables to  {0, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "_uuid": "f4ec7bc53e1233f856e5d5fe60d2681d88f881b1"
   },
   "outputs": [],
   "source": [
    "target_variable = tweets_df2['sentiment'].apply(lambda x: -1 if x=='neg' else (1 if x==\"pos\" else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "_uuid": "bae6f1c0864306af8264bcd4e74ab2d8ab9a8c17"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_word_feature, target_variable, test_size=0.3, random_state=272)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "R_model = randomforest.fit(X_train,y_train)\n",
    "R_predict=R_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "1-Confusion matrix <br>\n",
    "2-Accuray <br>\n",
    "3-F1 score <br>\n",
    "4-Other matrix<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[504 130  62]\n",
      " [ 52 343  29]\n",
      " [146 110 214]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "\n",
    "matrix = confusion_matrix(y_test,R_predict, labels=[1, 0,-1])\n",
    "print(\"Confusion matrix\")\n",
    "print(matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.72      0.72       696\n",
      "           0       0.59      0.81      0.68       424\n",
      "          -1       0.70      0.46      0.55       470\n",
      "\n",
      "    accuracy                           0.67      1590\n",
      "   macro avg       0.67      0.66      0.65      1590\n",
      "weighted avg       0.68      0.67      0.66      1590\n",
      "\n",
      "\n",
      "\n",
      "The accuracy of the model is =  0.6672955974842767\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test,R_predict,labels=[1,0,-1])\n",
    "print('\\nClassification report : \\n',matrix)\n",
    "\n",
    "# Accuracy\n",
    "print(\"\\n\\nThe accuracy of the model is = \", accuracy_score(y_test,R_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Logistic multiclass Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create logistic regression object\n",
    "logistic_regression = LogisticRegression(multi_class='multinomial', solver='newton-cg',random_state=0)\n",
    "# Train model\n",
    "L_model = logistic_regression.fit(X_train,y_train)\n",
    "L_predict=L_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "1-Confusion matrix <br>\n",
    "2-Accuray <br>\n",
    "3-F1 score <br>\n",
    "4-Other matrix<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[566  56  74]\n",
      " [140 239  45]\n",
      " [166  58 246]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test,L_predict, labels=[1,0,-1])\n",
    "#plot_confusion_matrix(matrix)\n",
    "print(\"Confusion matrix\")\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.81      0.72       696\n",
      "           0       0.68      0.56      0.62       424\n",
      "          -1       0.67      0.52      0.59       470\n",
      "\n",
      "    accuracy                           0.66      1590\n",
      "   macro avg       0.67      0.63      0.64      1590\n",
      "weighted avg       0.66      0.66      0.65      1590\n",
      "\n",
      "\n",
      "\n",
      "The accuracy of the model is =  0.6610062893081761\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test,L_predict,labels=[1,0,-1])\n",
    "print('\\nClassification report : \\n',matrix)\n",
    "\n",
    "# Accuracy\n",
    "print(\"\\n\\nThe accuracy of the model is = \", accuracy_score(y_test,L_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto'))\n",
    "clf.fit(X_train, y_train)\n",
    "svm_predict=clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Testing the model\n",
    "1-Confusion matrix <br>\n",
    "2-Accuray <br>\n",
    "3-F1 score <br>\n",
    "4-Other matrix<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[627  47  22]\n",
      " [263 142  19]\n",
      " [324  39 107]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test,svm_predict, labels=[1,0,-1])\n",
    "#plot_confusion_matrix(matrix)\n",
    "print(\"Confusion matrix\")\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.90      0.66       696\n",
      "           0       0.62      0.33      0.44       424\n",
      "\n",
      "   micro avg       0.53      0.69      0.60      1120\n",
      "   macro avg       0.57      0.62      0.55      1120\n",
      "weighted avg       0.56      0.69      0.57      1120\n",
      "\n",
      "\n",
      "\n",
      "The accuracy of the model is =  0.5509433962264151\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test,svm_predict,labels=[1,0])\n",
    "print('\\nClassification report : \\n',matrix)\n",
    "\n",
    "# Accuracy\n",
    "print(\"\\n\\nThe accuracy of the model is = \", accuracy_score(y_test,svm_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5- mask_senti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tweets</th>\n",
       "      <th>tidy_tweets</th>\n",
       "      <th>absolute_tidy_tweets</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-30 22:06:12+00:00</td>\n",
       "      <td>Social Distancing w/ @GAROFALI by @PatSupsiri ...</td>\n",
       "      <td>Social Distancing w/ @GAOFALI by @PatSupsiri</td>\n",
       "      <td>Social Distancing w GAOFALI PatSupsiri</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-30 21:09:12+00:00</td>\n",
       "      <td>Really impressed by @Jetstar_NZ strongly recom...</td>\n",
       "      <td>eally impressed by @Jetstar_NZ strongly recomm...</td>\n",
       "      <td>eally impressed JetstarNZ strongly recommendin...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-30 19:36:57+00:00</td>\n",
       "      <td>@EmilyQMD Great work @EmilyQMD In Australia we...</td>\n",
       "      <td>@EmilyQMD Great work @EmilyQMD In Australia we...</td>\n",
       "      <td>EmilyQMD Great work EmilyQMD In Australia weve...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       date  \\\n",
       "0           0  2020-10-30 22:06:12+00:00   \n",
       "1           1  2020-10-30 21:09:12+00:00   \n",
       "2           2  2020-10-30 19:36:57+00:00   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  Social Distancing w/ @GAROFALI by @PatSupsiri ...   \n",
       "1  Really impressed by @Jetstar_NZ strongly recom...   \n",
       "2  @EmilyQMD Great work @EmilyQMD In Australia we...   \n",
       "\n",
       "                                         tidy_tweets  \\\n",
       "0       Social Distancing w/ @GAOFALI by @PatSupsiri   \n",
       "1  eally impressed by @Jetstar_NZ strongly recomm...   \n",
       "2  @EmilyQMD Great work @EmilyQMD In Australia we...   \n",
       "\n",
       "                                absolute_tidy_tweets sentiment  \n",
       "0             Social Distancing w GAOFALI PatSupsiri   neutral  \n",
       "1  eally impressed JetstarNZ strongly recommendin...       pos  \n",
       "2  EmilyQMD Great work EmilyQMD In Australia weve...       pos  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df2=pd.read_csv(\"clean_soc_distanc_senti.csv\")\n",
    "tweets_df2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac943fa645c528c6cee36de60e9fbdd8be384cdd"
   },
   "source": [
    "## <a id='5'>5. Feature Extraction</a>\n",
    "\n",
    "We need to convert textual representation in the form on numeric features. We have a popular techniques to perform feature extraction:\n",
    "\n",
    "\n",
    "1. __TF-IDF (Term Frequency - Inverse Document Frequency)__\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "622ce8acd9e96e232d3a9b6d526ee7ca675f5a55"
   },
   "source": [
    "### <a id='5A'>A. Feature Extraction for 'Key Words'</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_uuid": "a92ca10bbce43b9a01faef3dff8b6bc5da5f8c6b"
   },
   "outputs": [],
   "source": [
    "# TF-IDF features\n",
    "tfidf_word_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, stop_words='english')\n",
    "# TF-IDF feature matrix\n",
    "tfidf_word_feature = tfidf_word_vectorizer.fit_transform(tweets_df2['absolute_tidy_tweets'].astype('U'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c374d7527da7c24177cc42e3c2b3b1a87c9e38a"
   },
   "source": [
    "## <a id='6'>6. Model Building: Sentiment Analysis</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ad9171efab73b4305acb6f29de3519285fbf9448"
   },
   "source": [
    "#### Map target variables to  {0, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_uuid": "f4ec7bc53e1233f856e5d5fe60d2681d88f881b1"
   },
   "outputs": [],
   "source": [
    "target_variable = tweets_df2['sentiment'].apply(lambda x: -1 if x=='neg' else (1 if x==\"pos\" else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "_uuid": "bae6f1c0864306af8264bcd4e74ab2d8ab9a8c17"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_word_feature, target_variable, test_size=0.3, random_state=272)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "R_model = randomforest.fit(X_train,y_train)\n",
    "R_predict=R_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "1-Confusion matrix <br>\n",
    "2-Accuray <br>\n",
    "3-F1 score <br>\n",
    "4-Other matrix<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[808 135  32]\n",
      " [140 451  10]\n",
      " [240  86 132]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "\n",
    "matrix = confusion_matrix(y_test,R_predict, labels=[1, 0,-1])\n",
    "print(\"Confusion matrix\")\n",
    "print(matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.83      0.75       975\n",
      "           0       0.67      0.75      0.71       601\n",
      "          -1       0.76      0.29      0.42       458\n",
      "\n",
      "    accuracy                           0.68      2034\n",
      "   macro avg       0.70      0.62      0.62      2034\n",
      "weighted avg       0.70      0.68      0.66      2034\n",
      "\n",
      "\n",
      "\n",
      "The accuracy of the model is =  0.683874139626352\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test,R_predict,labels=[1,0,-1])\n",
    "print('\\nClassification report : \\n',matrix)\n",
    "\n",
    "# Accuracy\n",
    "print(\"\\n\\nThe accuracy of the model is = \", accuracy_score(y_test,R_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Logistic Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create logistic regression object\n",
    "logistic_regression = LogisticRegression(multi_class='multinomial', solver='newton-cg',random_state=0)\n",
    "# Train model\n",
    "L_model = logistic_regression.fit(X_train,y_train)\n",
    "L_predict=L_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "1-Confusion matrix <br>\n",
    "2-Accuray <br>\n",
    "3-F1 score <br>\n",
    "4-Other matrix<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[849  85  41]\n",
      " [159 411  31]\n",
      " [197  74 187]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test,L_predict, labels=[1,0,-1])\n",
    "#plot_confusion_matrix(matrix)\n",
    "print(\"Confusion matrix\")\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.87      0.78       975\n",
      "           0       0.72      0.68      0.70       601\n",
      "          -1       0.72      0.41      0.52       458\n",
      "\n",
      "    accuracy                           0.71      2034\n",
      "   macro avg       0.72      0.65      0.67      2034\n",
      "weighted avg       0.71      0.71      0.70      2034\n",
      "\n",
      "\n",
      "\n",
      "The accuracy of the model is =  0.7114060963618486\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test,L_predict,labels=[1,0,-1])\n",
    "print('\\nClassification report : \\n',matrix)\n",
    "\n",
    "# Accuracy\n",
    "print(\"\\n\\nThe accuracy of the model is = \", accuracy_score(y_test,L_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto'))\n",
    "clf.fit(X_train, y_train)\n",
    "svm_predict=clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Testing the model\n",
    "1-Confusion matrix <br>\n",
    "2-Accuray <br>\n",
    "3-F1 score <br>\n",
    "4-Other matrix<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[910  61   4]\n",
      " [330 269   2]\n",
      " [396  22  40]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test,svm_predict, labels=[1,0,-1])\n",
    "#plot_confusion_matrix(matrix)\n",
    "print(\"Confusion matrix\")\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.93      0.70       975\n",
      "           0       0.76      0.45      0.56       601\n",
      "\n",
      "   micro avg       0.59      0.75      0.66      1576\n",
      "   macro avg       0.66      0.69      0.63      1576\n",
      "weighted avg       0.64      0.75      0.65      1576\n",
      "\n",
      "\n",
      "\n",
      "The accuracy of the model is =  0.5993117010816126\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test,svm_predict,labels=[1,0])\n",
    "print('\\nClassification report : \\n',matrix)\n",
    "\n",
    "# Accuracy\n",
    "print(\"\\n\\nThe accuracy of the model is = \", accuracy_score(y_test,svm_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6- clean_vaccine_senti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>tweets</th>\n",
       "      <th>tidy_tweets</th>\n",
       "      <th>absolute_tidy_tweets</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-30 21:43:08+00:00</td>\n",
       "      <td>@tls_fletcher Hope ➕decent president ➕vaccine ✅</td>\n",
       "      <td>@tls_fletcher Hope ➕decent president ➕vaccine ✅</td>\n",
       "      <td>tlsfletcher Hope decent president vaccine</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-30 15:43:24+00:00</td>\n",
       "      <td>would you date someone who..?\\n\\n1 - done \\n2 ...</td>\n",
       "      <td>would you date someone who..? 1 - done 2 - lyf...</td>\n",
       "      <td>would date someone done lyfe dont think nahh s...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-30 14:00:59+00:00</td>\n",
       "      <td>@CNBC They should offer free covid vaccines to...</td>\n",
       "      <td>@CNBC They should offer free covid vaccines to...</td>\n",
       "      <td>CNBC They offer free covid vaccine Apple Fanboys</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       date  \\\n",
       "0           0  2020-10-30 21:43:08+00:00   \n",
       "1           1  2020-10-30 15:43:24+00:00   \n",
       "2           2  2020-10-30 14:00:59+00:00   \n",
       "\n",
       "                                              tweets  \\\n",
       "0    @tls_fletcher Hope ➕decent president ➕vaccine ✅   \n",
       "1  would you date someone who..?\\n\\n1 - done \\n2 ...   \n",
       "2  @CNBC They should offer free covid vaccines to...   \n",
       "\n",
       "                                         tidy_tweets  \\\n",
       "0    @tls_fletcher Hope ➕decent president ➕vaccine ✅   \n",
       "1  would you date someone who..? 1 - done 2 - lyf...   \n",
       "2  @CNBC They should offer free covid vaccines to...   \n",
       "\n",
       "                                absolute_tidy_tweets sentiment  \n",
       "0          tlsfletcher Hope decent president vaccine       pos  \n",
       "1  would date someone done lyfe dont think nahh s...       neg  \n",
       "2   CNBC They offer free covid vaccine Apple Fanboys       pos  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df2=pd.read_csv(\"clean_vaccine_senti.csv\")\n",
    "tweets_df2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac943fa645c528c6cee36de60e9fbdd8be384cdd"
   },
   "source": [
    "## <a id='5'>5. Feature Extraction</a>\n",
    "\n",
    "We need to convert textual representation in the form on numeric features. We have a popular techniques to perform feature extraction:\n",
    "\n",
    "\n",
    "1. __TF-IDF (Term Frequency - Inverse Document Frequency)__\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "622ce8acd9e96e232d3a9b6d526ee7ca675f5a55"
   },
   "source": [
    "### <a id='5A'>A. Feature Extraction for 'Key Words'</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "_uuid": "a92ca10bbce43b9a01faef3dff8b6bc5da5f8c6b"
   },
   "outputs": [],
   "source": [
    "# TF-IDF features\n",
    "tfidf_word_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, stop_words='english')\n",
    "# TF-IDF feature matrix\n",
    "tfidf_word_feature = tfidf_word_vectorizer.fit_transform(tweets_df2['absolute_tidy_tweets'].astype('U'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c374d7527da7c24177cc42e3c2b3b1a87c9e38a"
   },
   "source": [
    "## <a id='6'>6. Model Building: Sentiment Analysis</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ad9171efab73b4305acb6f29de3519285fbf9448"
   },
   "source": [
    "#### Map target variables to  {0, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "_uuid": "f4ec7bc53e1233f856e5d5fe60d2681d88f881b1"
   },
   "outputs": [],
   "source": [
    "target_variable = tweets_df2['sentiment'].apply(lambda x: -1 if x=='neg' else (1 if x==\"pos\" else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "_uuid": "bae6f1c0864306af8264bcd4e74ab2d8ab9a8c17"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_word_feature, target_variable, test_size=0.3, random_state=272)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "R_model = randomforest.fit(X_train,y_train)\n",
    "R_predict=R_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "1-Confusion matrix <br>\n",
    "2-Accuray <br>\n",
    "3-F1 score <br>\n",
    "4-Other matrix<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[183  31  49]\n",
      " [ 36  98   9]\n",
      " [ 85  30  88]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "\n",
    "matrix = confusion_matrix(y_test,R_predict, labels=[1, 0,-1])\n",
    "print(\"Confusion matrix\")\n",
    "print(matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.70      0.65       263\n",
      "           0       0.62      0.69      0.65       143\n",
      "          -1       0.60      0.43      0.50       203\n",
      "\n",
      "    accuracy                           0.61       609\n",
      "   macro avg       0.61      0.60      0.60       609\n",
      "weighted avg       0.61      0.61      0.60       609\n",
      "\n",
      "\n",
      "\n",
      "The accuracy of the model is =  0.6059113300492611\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test,R_predict,labels=[1,0,-1])\n",
    "print('\\nClassification report : \\n',matrix)\n",
    "\n",
    "# Accuracy\n",
    "print(\"\\n\\nThe accuracy of the model is = \", accuracy_score(y_test,R_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Logistic Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create logistic regression object\n",
    "logistic_regression = LogisticRegression(multi_class='multinomial', solver='newton-cg',random_state=0)\n",
    "# Train model\n",
    "L_model = logistic_regression.fit(X_train,y_train)\n",
    "L_predict=L_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "1-Confusion matrix <br>\n",
    "2-Accuray <br>\n",
    "3-F1 score <br>\n",
    "4-Other matrix<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[219   3  41]\n",
      " [105  16  22]\n",
      " [111   2  90]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test,L_predict, labels=[1,0,-1])\n",
    "#plot_confusion_matrix(matrix)\n",
    "print(\"Confusion matrix\")\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.83      0.63       263\n",
      "           0       0.76      0.11      0.20       143\n",
      "          -1       0.59      0.44      0.51       203\n",
      "\n",
      "    accuracy                           0.53       609\n",
      "   macro avg       0.62      0.46      0.44       609\n",
      "weighted avg       0.59      0.53      0.49       609\n",
      "\n",
      "\n",
      "\n",
      "The accuracy of the model is =  0.5336617405582923\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test,L_predict,labels=[1,0,-1])\n",
    "print('\\nClassification report : \\n',matrix)\n",
    "\n",
    "# Accuracy\n",
    "print(\"\\n\\nThe accuracy of the model is = \", accuracy_score(y_test,L_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto'))\n",
    "clf.fit(X_train, y_train)\n",
    "svm_predict=clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Testing the model\n",
    "1-Confusion matrix <br>\n",
    "2-Accuray <br>\n",
    "3-F1 score <br>\n",
    "4-Other matrix<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[241  13   9]\n",
      " [ 95  46   2]\n",
      " [167  15  21]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "matrix = confusion_matrix(y_test,svm_predict, labels=[1,0,-1])\n",
    "#plot_confusion_matrix(matrix)\n",
    "print(\"Confusion matrix\")\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.92      0.63       263\n",
      "           0       0.62      0.32      0.42       143\n",
      "\n",
      "   micro avg       0.50      0.71      0.58       406\n",
      "   macro avg       0.55      0.62      0.53       406\n",
      "weighted avg       0.53      0.71      0.56       406\n",
      "\n",
      "\n",
      "\n",
      "The accuracy of the model is =  0.5057471264367817\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test,svm_predict,labels=[1,0])\n",
    "print('\\nClassification report : \\n',matrix)\n",
    "\n",
    "# Accuracy\n",
    "print(\"\\n\\nThe accuracy of the model is = \", accuracy_score(y_test,svm_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
